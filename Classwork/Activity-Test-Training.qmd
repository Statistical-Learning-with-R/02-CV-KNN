---
title: "Test and Training Error"
author: "YOUR NAME HERE"
format: 
  html:
    code-fold: true
    code-line-numbers: true
    code-tools: true
    self-contained: true
editor: visual
execute:
  message: false
---

```{r, eval = TRUE, version = "none"}
templar::versions_quarto_multilingual(global_eval = FALSE, to_jupyter = TRUE, warn_edit = FALSE)
```

## Setup

Declare your libraries:

```{r, version = "R"}
#| label: libraries-r
#| include: false
library(tidyverse)
library(tidymodels)
```

```{python, version = "python"}
#| label: libraries-py
#| include: false
import pandas as pd
import numpy as np
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
```

## Code from slides

```{r, version = "R"}
ins <- read_csv("https://www.dropbox.com/s/bocjjyo1ehr5auz/insurance_costs_1.csv?dl=1")
head(ins)
```

```{python, version = "python"}
ins = pd.read_csv("https://www.dropbox.com/s/bocjjyo1ehr5auz/insurance_costs_1.csv?dl=1")
ins.head()
```

```{r, version = "R"}
lr_mod <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")

poly_mod_1 <- lr_mod %>%
  fit(charges ~ bmi, data = ins)


poly_mod_20 <- lr_mod %>%
  fit(charges ~ poly(bmi, 20), data = ins)
```

```{python, version = "python"}
poly_mod_1 = np.polyfit(x = ins["bmi"], y = ins[["charges"]], deg = 1)
poly_mod_20 = np.polyfit(x = ins["bmi"], y = ins[["charges"]], deg = 20)
```

```{r, version = "R"}
ins <- ins %>%
  mutate(
    preds_1 = predict(poly_mod_1, 
                      new_data = ins, 
                      type = "raw"),
    preds_20 = predict(poly_mod_20, 
                       new_data = ins, 
                       type = "raw")
  )
```

```{python, version = "python"}
ins['preds_1'] = np.polyval(poly_mod_1, x = ins["bmi"])
ins['preds_20'] = np.polyval(poly_mod_20, x = ins["bmi"])
```

```{r, version = "R"}
poly_mod_1$fit %>% summary()
poly_mod_20$fit %>% summary()
```

```{python, version = "python"}
print(poly_mod_1)
print(poly_mod_20)
```

```{r, version = "R"}
ins %>% 
  rmse(truth = charges, 
          estimate = preds_1)
ins %>% 
  rmse(truth = charges, 
          estimate = preds_20)
```

```{python, version = "python"}
absError = ins['preds_1'] - ins['charges']
SE = np.square(absError) # squared errors
MSE = np.mean(SE) # mean squared errors
np.sqrt(MSE) # Root Mean Squared Error, RMSE


absError = ins['preds_20'] - ins['charges']
SE = np.square(absError) # squared errors
MSE = np.mean(SE) # mean squared errors
np.sqrt(MSE)
```

```{r, version = "R"}
ins %>% 
  ggplot() +
  geom_point(aes(x = bmi, y = charges)) +
  geom_line(aes(x = bmi, y = preds_20),
            color = "red") +
  geom_line(aes(x = bmi, y = preds_1),
            color = "blue")

```

```{r, version = "R"}
# Set seed, so our "randomness" is consistent
set.seed(190498)

# Establish division of data
ins_split <- ins %>% initial_split()

# Save test and training as separate datasets

ins_test <- ins_split %>% testing()
ins_train <- ins_split %>% training()

# Check what happened

dim(ins_test)
dim(ins_train)
```

```{python, version = "python"}
import random
random.seed(190498)

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(ins['bmi'], ins['charges'])
```

```{r, version = "R"}
poly_mod_1 <- lr_mod %>%
  fit(charges ~ bmi, data = ins_train)


poly_mod_20 <- lr_mod %>%
  fit(charges ~ poly(bmi, 20), data = ins_train)

ins_test <- ins_test %>%
  mutate(
    preds_1 = predict(poly_mod_1, 
                      new_data = ins_test, 
                      type = "raw"),
    preds_20 = predict(poly_mod_20, 
                       new_data = ins_test, 
                       type = "raw")
  )
```

```{python, version = "python"}
poly_mod_1 = np.polyfit(x = x_train, y = y_train, deg = 1)
poly_mod_20 = np.polyfit(x = x_train, y = y_train, deg = 20)

test_preds_1 = np.polyval(poly_mod_1, x = x_test)
test_preds_20 = np.polyval(poly_mod_20, x = x_test)
```

```{r, version = "R"}
ins_test %>% 
  rmse(truth = charges, 
          estimate = preds_1)

ins_test %>% 
  rmse(truth = charges, 
          estimate = preds_20)
```

```{python, version = "python"}
absError = test_preds_1 - y_test
SE = np.square(absError) # squared errors
MSE = np.mean(SE) # mean squared errors
np.sqrt(MSE) # Root Mean Squared Error, RMSE


absError = test_preds_20 - y_test
SE = np.square(absError) # squared errors
MSE = np.mean(SE) # mean squared errors
np.sqrt(MSE)
```

## Your turn

Suppose you want to fit a regression that predicts `charges` from `age` and `bmi`.

Consider four models:

-   `age` and `bmi` both have polynomial 1
-   `age` has polynomial 1, `bmi` has polynomial 2
-   `age` has polynomial 2, `bmi` has polynomial 1
-   `age` and `bmi` both have polynomial 2

(No interactions term for any model.)

Which model is best according to the **adjusted R-squared** on the training data?

Which model is best according to the **MSE** of the **test** data?
